{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "openai_client = openai.Client(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 1536\n",
    "embedding_model = \"text-embedding-3-small\"\n",
    "collection_name = \"gates_notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=dimensions, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "# Read a PDF file and split its content into chunks of text\n",
    "def read_pdf_chunks(file_path, chunk_size=1000):\n",
    "    chunks = []\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            # Split text into chunks\n",
    "            for i in range(0, len(text), chunk_size):\n",
    "                chunks.append(text[i:i+chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# List all files in the directory\n",
    "pdf_directory = './gates_notes'\n",
    "pdf_files = [file for file in os.listdir(pdf_directory) if file.endswith('.pdf')]\n",
    "\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    year = pdf_file[:4]\n",
    "\n",
    "    pdf_file_path = os.path.join(pdf_directory, pdf_file)\n",
    "    chunk_size = 1000  # Number of characters per chunk\n",
    "\n",
    "    pdf_chunks = read_pdf_chunks(pdf_file_path, chunk_size)\n",
    "\n",
    "    result = openai_client.embeddings.create(input=pdf_chunks, model=embedding_model, dimensions=dimensions)\n",
    "\n",
    "    # Format data using PointStruct\n",
    "    points = [\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=data.embedding,\n",
    "            payload={\n",
    "                \"year\": year,\n",
    "                \"title\": pdf_file,\n",
    "                \"text\": ''.join(pdf_chunks),\n",
    "            },\n",
    "        )\n",
    "        for idx, (data) in enumerate(result.data)\n",
    "    ]\n",
    "\n",
    "    print(points)\n",
    "\n",
    "    client.upsert(collection_name, points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_qdrant(query, top_k=1):\n",
    "\n",
    "    embedded_query = openai_client.embeddings.create(\n",
    "        input=query,\n",
    "        model=embedding_model,\n",
    "        dimensions=dimensions,\n",
    "    ).data[0].embedding\n",
    "    \n",
    "    query_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=(\n",
    "            embedded_query\n",
    "        ),\n",
    "        limit=top_k,\n",
    "    )\n",
    "    \n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = query_qdrant('Highest impact year')\n",
    "for i, article in enumerate(query_results):\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [r.payload['text'] for r in query_results]\n",
    "input_text = ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "custom_prompt = \"What did the Gates Foundation accomplish that year?\"\n",
    "\n",
    "template = PromptTemplate(template=\"{query} Context: {context}\", input_variables=[\"query\", \"context\"])\n",
    "prompt_with_context = template.invoke({\"query\": custom_prompt, \"context\": input_text})\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "results = llm.invoke(prompt_with_context)\n",
    "print(results.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj-ai-1-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
